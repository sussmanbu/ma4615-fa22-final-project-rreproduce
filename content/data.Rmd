---
title: Data
description:
toc: true
featuredVideo:
featuredImage: images/data-import-cheatsheet-thumbs.png
draft: false
---

## Data Link
Primary: https://migrationpatterns.org/ (Migration Trend)


Secondary: https://ucr.fbi.gov/hate-crime (Crime Data)


When we first started the project, we tried to explore what parameters influence the immigration decisions (race, parents income, other datasets maybe education level, marriage, city GDP, government policy, tax rate, weather). There are lots of dataset that study the migration trend. We specifically focus on the young adult migration trend. The dataset is mainly constructed by three organizations: Policy Impacts, Opportunity Insights and United States Census Bureau to analyze the trend people migrate between childhood and young adulthood and further analyze how much one's location during childhood determines the labor markets that one is exposed to in young adulthood,etc. 
Looking more closely into the data collection process, the data about location at age 16 and 26 is assigned using Census, tax, and HUD information. Child race is measured using information from the 2010 Decennial Census and American Community Survey (ACS). Parental income is measured as a 5-year average of family income when the children are aged 14-18 based on the tax form 1040 of the parent who claims them as a dependent.  


The second data set is about crime rate data. This dataset is from the FBI website in the hate crime category. The dataset is collected and constructed by the US government.


We care about social justice in the United States. We hope to find out how migration would impact the change of the crime rate in the United States between two ranges: year 2000 - year 2008, year 2010 - year 2018. Additionally, we are interested in finding out whether other variables would moderate the association between migration pattern and crime rate, such as income levels, race,and the geographic locations.By combining two dataset and the variables we want to use, we finalize our research question: how different parameters affect the migration pattern and their relationship with others. 


## Variables

The migration dataset contains 9 variables. 


Geographic variables: 

* origin commuting zone (o_cz) : The numeric identifier of the commuting zone (CZ) in which the individual resided in childhood/at age 16 (referred to as origin CZ hereafter).
* O_state : The name of the state the origin CZ is in.
* destination commuting zone (d_cz): The numeric identifier of the CZ in which the individual resides in young adulthood/at age 26 (referred to as destination CZ hereafter).
* D_state: The name of the state the origin CZ is in.
Migration variables : 
* parental income quintile(Q1-Q5)
* race
* number of people from o now living in d
* number of people living in d
* number of people from o


We used 4 variables listed below:

*	resident number before migration by state (numeric)
*	resident number after migration by state (numeric)
*	original family income (categorical; from Q1 to Q5)
*	Race (categorical:Asian, Black, Hispanic, White, Other)


The crime dataset contains 13 variables, including different kinds of hate crime, such as violent crime, property crime,robbery, burglary, etc. 


We used 3 variables from the dataset: 

*	State (nominal; 50 in total)
*	Mean number of robbery cases by states (numeric) in two year range : 2000- 2008, 2010-2018.
*	Mean number of burglary cases by states from year 2000 to year 2008 , and from year 2010 to year 2018. 



## Data Import and Cleaning

After importing our primary dataset od.csv, we first separate the "pool" column into "race" and "income"

```{r}
## pool     ->    race    |   income
## WhiteQ1  ->   White    |     Q1
```

Next we filter out 0 values from 'n' column (indicating that the path has no immigrants) and -1 and NA values from all cells (invalid number)

```{r}
##   filter(n != 0 & n != -1) 
##   filter(n_tot_o != -1) 
##   filter(n_tot_d != -1)
##   od_data[is.na(od_data)] = 0
```


To explore the data structure and out interests in the dataset, we have also created a sub dataset that contains people moved from MA to other states/stayed in MA. (see o_MA)


Our secondary data is separated in multiple files range from different years and each row represents different information by state. 
Therefore, we only extracted the row indicating the total cases of crime categories of all states.
Crime categories do not have data for every year except for "Robbery" and "Burglary". For the consistency of the analysis, we only use case numbers of "Robbery" and "Burglary" for analysis. 

```{r}
## For instance: 2010 Crime Data import:
## data2010<- data2010 %>% fill(State) %>% fill(Area) %>% filter(Area == 'State Total') %>% 
## filter(...3== 'Rate per 100,000 inhabitants') %>% select(-Population,-...3)
## data2010 <- data2010[, colSums(is.na(data2010)) < nrow(data2010)]

## Crime data from 2000-2003 use different formats:
## data2003 <- read_csv(here::here("dataset", "2003.csv"),skip = 4)%>% 
##   filter(Area!= 'Metropolitan Statistical Area'&
##           Area!='Area actually reporting'&
##           Area!='Estimated totals'&
##           Area!='Cities outside metropolitan areas'&
##           Area!='Rural'&
##           Area!='State Total'&
##           Area!='Total'&
##           Area!='Nonmetropolitan counties'&
##           Area!='Estimated total') %>% 
##   select(c(Area,Robbery,Burglary))
## data2003$Area <- gsub('Rate per 100,000 inhabitants', NA, data2003$Area) 
## data2003 <- data2003 %>% 
##   fill(Area) %>%
##   drop_na(Robbery, Burglary)
```

Then we merged crime data from 2000-2007 and 2010-2017 into two datasets, each dataset is composed of state name and average crime cases. This is because this data is collected when these people were at age 16 and 26 and they were born between between 1984-1992. So we have calculated the time period of these people at age 16 and 26 to seperate the datasets. Note that crime data for year 2004 is missing on the website so we skiped that year during the analysis(since we are using the average it should not be an issue).

```{r}
## Combine 2000-2007 crime data
## df_list <- list(data2000, data2001, data2002,data2003,data2005,data2006,data2007)
## mergedf <- Reduce(function(x, y) merge(x, y, all=TRUE), df_list)
## mergedf$Area <- gsub('[0-9., ]', '', mergedf$Area)
## mergedf <- mergedf %>%
##   group_by(Area) %>%
##   summarize(meanRobbery = mean(as.numeric(Robbery)),meanBurglary = mean(Burglary))
```

And the merged dataset is now ready for analysis. 

link to [loaddata.R](https://rreproduce.netlify.app/loaddata.R)


## Shiny Interactive

We have not developed the Shiny interactive yet but we have our ideas listed below:

1. Firstly we want to use one plot graph to show the relationship between crime rate and income level in each state. Specifically, we will use the majority income level to represent each state (for example, if the population of income level in Q1 is the biggest in the state, then A will be shown as Q1 income level). Most people will assume that the less the income level, the more crime rate. However, there is no significant relationship between those two variables
2. Then, we will use the crosstalk function to make users see the crime rate and migration rate in each state. Users can playing with the selection button on the map to filter different regions among five regions: Northeast, Midwest, South, and West; as well as coastal and noncoastal. Users can also choose the migration rate range in the Magnitude to find corresponding states
3. Finally, if users are interested in predicting their future living location, they can input their personal information on 16-years-old: state, income level, and race, and the website will return the prediction result. 
Or if users are elder than 26, they can also use this to check whether they follow the trend of migration. If wrong, we will ask users whether to provide their informations to help us improve our model.




----

## Rubric: On this page (kept for reference)

you will

* Describe where/how to find data.
  * You must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.
  * Why was the data collected/curated? Who put it together? (This is important, if you don't know why it was collected then that might not be a good dataset to look at.
* Describe the different data files used and what each variable means. 
  * If you have many variables then only describe the most relevant ones and summarize the rest.
* Describe any cleaning you had to do for your data.
  * You *must* include a link to your `load_and_clean_data.R` file.
  * Also, describe any additional R packages you used outside of those covered in class.
  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.
  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.
* Organization, clarity, cleanliness of the page
  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.