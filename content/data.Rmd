---
title: Data
description:
toc: true
featuredVideo:
featuredImage: images/data-import-cheatsheet-thumbs.png
draft: false
---

Data Link

We care about the social justice in the United States. We hope to find out how migration would impact the change of the crime rate in the United States between (year1) and (year 2). Additionally, we are interested in find out whether other variables would moderate the association between migration pattern and crime rate, such as income levels and race.
Our migration data is from the [XXX]. We assorted the data in to several different data set, including [XXX]. Specifically, we used [sub-dataset 1], which describes [XXX], and [sub-dataset 2], which describes [XXX] to construct our models. Our crime rate data is from the [XXX]. We assorted our data into the number of “rubbery” and “bulglary” cases during [Year] by the states in the US.
Here are the links of the two data sets that we used: [Link].

Variables

The migration dataset contains # variables. We used # variables listed below:
1.	resident number before migration by state (numeric)
2.	resident number after migration by state (numeric)
3.	original family income (categorical; from Q1 to Q5)
4.	Race (categorical; [describe the race])
5.	......

The crime rate dataset contains 3 variables.
1.	State (nominal; 50 in total)
2.	Mean number of rubbery cases by states (numeric) in (year)
3.	Mean number of bulglary cases by states in (year)

Specific Created Variables


Data Import and Cleaning

After importing our primary dataset od.csv, we first separate the "pool" column into "race" and "income"

```{r}
## pool     ->    race    |   income
## WhiteQ1  ->   White    |     Q1
```

Next we filter out 0 values from 'n' column (indicating that the path has no immigrants) and -1 and NA values from all cells (invalid number)

```{r}
##   filter(n != 0 & n != -1) 
##   filter(n_tot_o != -1) 
##   filter(n_tot_d != -1)
##   od_data[is.na(od_data)] = 0
```


Our secondary data is separated in multiple files range from different years and each row represents different information by state. 
Therefore, we only extracted the row indicating the total cases of crime categories of all states.
Crime categories do not have data for every year except for "Robbery" and "Burglary". For the consistency of the analysis, we only use case numbers of "Robbery" and "Burglary" for analysis.
```{r}
## For instance: 2010 Crime Data import:
## data2010<- data2010 %>% fill(State) %>% fill(Area) %>% filter(Area == 'State Total') %>% 
## filter(...3== 'Rate per 100,000 inhabitants') %>% select(-Population,-...3)
## data2010 <- data2010[, colSums(is.na(data2010)) < nrow(data2010)]

## Crime data from 2000-2003 use different formats:
## data2003 <- read_csv(here::here("dataset", "2003.csv"),skip = 4)%>% 
##   filter(Area!= 'Metropolitan Statistical Area'&
##           Area!='Area actually reporting'&
##           Area!='Estimated totals'&
##           Area!='Cities outside metropolitan areas'&
##           Area!='Rural'&
##           Area!='State Total'&
##           Area!='Total'&
##           Area!='Nonmetropolitan counties'&
##           Area!='Estimated total') %>% 
##   select(c(Area,Robbery,Burglary))
## data2003$Area <- gsub('Rate per 100,000 inhabitants', NA, data2003$Area) 
## data2003 <- data2003 %>% 
##   fill(Area) %>%
##   drop_na(Robbery, Burglary)
```

Then we merged crime data from 2000-2007 and 2010-2017 into two datasets, each dataset is composed of state name and average crime cases.

```{r}
## Combine 2000-2007 crime data
## df_list <- list(data2000, data2001, data2002,data2003,data2005,data2006,data2007)
## mergedf <- Reduce(function(x, y) merge(x, y, all=TRUE), df_list)
## mergedf$Area <- gsub('[0-9., ]', '', mergedf$Area)
## mergedf <- mergedf %>%
##   group_by(Area) %>%
##   summarize(meanRobbery = mean(as.numeric(Robbery)),meanBurglary = mean(Burglary))
```

And the merged dataset is now ready for analysis. 

## Files in static

### `load_and_clean_data.R`

The idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them.
This file might create a derivative data set that you then use for your subsequent analysis.
Note that you don't need to run this script from every post/page.
Instead, you can load in the results of this script, which could be plain text files or `.RData` files. In your data page you'll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes.
To link to this file, you can use `[cleaning script](/load_and_clean_data.R)`. 


When you are loading in data, I recommend using the `here::here` function to specify the file path. This function is used to specify a path relative to your project's root directory. Hence, you can read a file using eg, `read_csv(here::here("dataset/data_file.csv"))`.


### Shiny Interactive

If you are using a shiny interactive, you'll need to keep that in a separate folder (i.e. not in `static` or `content`). For the shiny interactive you'll need to publish the app on `shinyapps.io` where the app can be run. When you publish, make sure to include any data sets you are loading in among the files you publish since those datasets will need to be loaded by your app. 





----

## Rubric: On this page

you will

* Describe where/how to find data.
  * You must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.
  * Why was the data collected/curated? Who put it together? (This is important, if you don't know why it was collected then that might not be a good dataset to look at.
* Describe the different data files used and what each variable means. 
  * If you have many variables then only describe the most relevant ones and summarize the rest.
* Describe any cleaning you had to do for your data.
  * You *must* include a link to your `load_and_clean_data.R` file.
  * Also, describe any additional R packages you used outside of those covered in class.
  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.
  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.
* Organization, clarity, cleanliness of the page
  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.