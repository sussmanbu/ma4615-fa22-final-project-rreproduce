---
title: Data
description:
toc: true
authors: []
tags: []
categories: []
series: []
date: 2022-12-13T16:42:03-05:00
lastmod: 2022-12-13T16:42:03-05:00
featuredVideo:
featuredImage:
draft: false
---

<font size="5"><b>Data Import and Cleaning</b></font>

We save our migration dataset "od.csv" in the folder "dataset-ignore" since it is a large file (>1GB). After importing "od.csv", we separate the "pool" column into "race" and "income". Next we filter out -1 and NA values (missing data) from all cells. We did not filter out 0 because a lack of migration might also be interesting and meaningful. 
```{r eval=FALSE, message=FALSE, warning=FALSE}
od_data <- read_csv(here::here("dataset-ignore", "od.csv")) %>%
  separate(pool,
           into = c("race","income"),
           sep = -2
  ) %>%
  filter(n != -1) %>%
  filter(n_tot_o != -1) %>%
  filter(n_tot_d != -1) 
od_data[is.na(od_data)] <- 0
write.csv(od_data,file=here::here("dataset-ignore/od_data.csv"),row.names=FALSE)
```


To explore the data structure and our interests in migration pattern, we have also created a sub-dataset that contains people whose origin in MA. (see o_MA below). This method can be applied to other states as well.   

```{r eval=FALSE, message=FALSE, warning=FALSE}
o_MA <- od_data %>% 
  filter(o_state_name == "Massachusetts")   #Can change "Massachusetts" to other state names
write_csv(o_MA, file = here::here("dataset", "o_MA.csv"))
```


Since observations in our secondary and third datasets are measured by state, we decide to combine the commuter zones into states. We make two datasets: 'leave' and 'movein'. 'leave' contains the state number and proportion of 16 year-old population who are in other states at the age of 26. 'movein' contain the state number and proportion of 26 year-old population who are in other state at the age of 16. 


To obtain 'leave' data, we group by the origin state name and calculate the total state population measured when they were at the origin (at age 16). Then we filter out the observation which have the same origin and destination state. By doing so, we exclude the observation who did not migrate to other states. We group by origin state again and calculate the total population who left the state. We calculate the leave proportion by dividing the leaving population by total population.

Similarly, for 'movein' data, we group by the destination state and calculate the total state population measured when they were at the destination (at  age 26). Then we filter out the observation which have the same origin and destination state. By doing so, we exclude the observation who are from the same state. We group by destination state again and calculate the total population who move into this state. We calculate the move in proportion by dividing the moving in population by total population.
```{r eval=FALSE, message=FALSE, warning=FALSE}
## LEAVE FROM STATE ##
leave <-od_data %>% 
  group_by(o_state_name) %>%
  mutate(total = sum(n)) %>%
  ungroup() %>%
  filter(o_state_name != d_state_name) %>% group_by(o_state_name) %>% 
  summarise(leave_pop = sum(n),total_pop = total, proportion = sum(n)/total) %>%
  distinct(o_state_name,.keep_all = T) 
write_csv(leave, file = here::here("dataset", "leave.csv"))

## MOVE INTO STATE ##
movein <- od_data %>% 
  group_by(d_state_name) %>%
  mutate(total = sum(n)) %>%
  filter(o_state_name != d_state_name) %>% group_by(d_state_name) %>% 
  summarise(movein_pop = sum(n),total_pop = total,proportion = sum(n)/total) %>%
  distinct(d_state_name,.keep_all = T)
write_csv(movein, file = here::here("dataset", "movein.csv"))
```



Our secondary dataset is separated in multiple files by different years. We only extract the row indicating the Rate per 100,000 inhabitants of crime categories of all states so that each row represents different information by state. 
Crime categories do not have data for every year except for "Robbery" and "Burglary". For the consistency of the analysis, we only use crime rate of "Robbery" and "Burglary" for analysis. 

```{r eval=FALSE, message=FALSE, warning=FALSE}
## Use the following method for cleaning crime dataset 2010-2017 and 2005-2007
data2010 <- read_csv(here::here("dataset/crime2010-2017", "2010-table-5.csv"),skip = 3)%>% fill(State) %>% fill(Area) %>% filter(Area == 'State Total') %>% filter(...3== 'Rate per 100,000 inhabitants') %>% select(-Population,-...3)
data2010 <- data2010[, colSums(is.na(data2010)) < nrow(data2010)] %>% mutate(year = '2010')

## Crime data from 2000-2003 use different methods:
data2000 <- read_csv(here::here("dataset/crime2000-2007", "2000.csv"),skip = 3)%>% 
  filter(!Area%in% c('Metropolitan Statistical Area','Area actually reporting','Estimated totals','Cities outside metropolitan areas','Rural','State Total','Total'))%>%select(c(Area,Robbery,Burglary))
data2000$Area <- gsub('Rate per 100,000 inhabitants', NA, data2000$Area) 
data2000 <- data2000 %>% fill(Area) %>% drop_na(Robbery, Burglary)%>% mutate(year='2000')
```


Then we merged crime data from 2000-2007 and 2010-2017 into two lists, use reduce() to iterate dataframes in list, and use merge(x,y) functions to combine dataframes by common column names. Then we use gsub() to remove extra numbers and space in States column, select "State", "Robbery", "Burglary", and "year" columns, and arrange rows by years. We also use group_by() and summarize() to calculate the mean robbery and mean burglary cases. 

```{r eval=FALSE, message=FALSE, warning=FALSE}
df_list <- list(data2010, data2011, data2012,data2013,data2014,data2015,data2016,data2017)
mergedf <- Reduce(function(x, y) merge(x, y, all=TRUE), df_list)
mergedf$State <- gsub('[0-9., ]', '', mergedf$State)
crime1017 <- mergedf %>% select(c(State,Robbery,Burglary,year)) %>% arrange(year)
averagecrime1017<-crime1017 %>% group_by(State) %>%summarize(meanRobbery = mean(Robbery),meanBurglary = mean(Burglary))
```

Migration data is collected when these people were at age 16 and 26. These people were born between 1984-1992. We calculate the time period of these people at age 16 and 26 and find the crime data corresponding two time periods. Note that crime data for year 2004 is missing on the website so we skipped that year for the analysis(since we are using the average it should not be an issue).


Our third dataset is the US colleges and University dataset. First, we filter the observation so that only schools within the U.S. are kept. Next, we select the columns: NAME,STATE,NAICS_DESC,COUNTRY (School name, school types, and school locations)

```{r eval=FALSE, message=FALSE, warning=FALSE}
## Read US colleges and University dataset and select variables
Uni <- read_delim(here::here('dataset','us-colleges-and-universities.csv'),delim=';') %>%
  filter(COUNTRY == 'USA') %>%
  select(NAME,CITY,STATE,NAICS_DESC) 
write_csv(Uni, file = here::here("dataset", "Uni.csv"))
```

We want to analyze schools by state, so we further clean the university dataset. We first group by different states and different types of school to calculate the number of schools in different categories in each state. Then we pivot_wider NAICS_DESC type of schools into columns so that we could rename the types using shorter names. We pivot them back into the "type" column. 
```{r eval=FALSE, message=FALSE, warning=FALSE}
StateUni <- Uni %>%
  group_by(NAICS_DESC,STATE) %>%
  summarize(n=n())%>%
  pivot_wider(names_from = NAICS_DESC, values_from = 1) %>%
  rename(Business='BUSINESS AND SECRETARIAL SCHOOLS',
         General='COLLEGES, UNIVERSITIES, AND PROFESSIONAL SCHOOLS',
         Computer='COMPUTER TRAINING',
         Cosme_Barber='COSMETOLOGY AND BARBER SCHOOLS',
         EduServ='EDUCATIONAL SUPPORT SERVICES',
         Arts='FINE ARTS SCHOOLS',
         Flight='FLIGHT TRAINING',
         Junior='JUNIOR COLLEGES',
         Other='OTHER TECHNICAL AND TRADE SCHOOLS') %>%
  pivot_longer(c(Business,General,Computer,Cosme_Barber,EduServ,Arts,Flight,Junior,Other),names_to = 'type',values_to='value') %>%
  drop_na() %>%
  select(STATE,type,n)
write_csv(StateUni, file = here::here("dataset", "StateUni.csv"))
```

To simplify the process of analyzing data by state, we combine 'leave', 'movein', crime rates in early (2000-2007) and later (2010-2017) years, and university data to make a new collective dataset called 'state'. we use inner join by state names to combine the datasets. 
```{r eval=FALSE, message=FALSE, warning=FALSE}
uni <- read_csv(here::here("dataset/StateUni.csv")) %>%
  group_by(STATE) %>%
  mutate(state_sum = sum(n)) %>% 
  pivot_wider(names_from = type,values_from=n)
uni[is.na(uni)] <- 0
state <- st_read(here::here("dataset","cb_2019_us_state_20m/cb_2019_us_state_20m.shp")) %>%
  select(STUSPS,NAME) %>% rename(STATE = STUSPS)
state_uni <- inner_join(uni,state,by='STATE') %>%
  ungroup() %>%
  select(-'STATE')
movein_crime <- read_csv(here::here("dataset/10-17CrimeAvg.csv")) %>% rename(NAME = State)
leave_crime <- read_csv(here::here("dataset/00-07CrimeAvg.csv")) %>% rename(NAME = Area)
leave <- read_csv(here::here("dataset","leave.csv")) %>%
  select(-total_pop) %>%
  rename(NAME = o_state_name,leave_prop=proportion) 
movein <- read_csv(here::here("dataset","movein.csv")) %>%
  select(-total_pop) %>%
  rename(NAME = d_state_name,movein_prop=proportion)
state <- inner_join(state_uni,leave,by="NAME") %>%
  inner_join(movein,by="NAME") %>% ungroup() %>% mutate(NAME=toupper(NAME)) 
state$NAME <- gsub(' ','',state$NAME)
state <- state_full %>% inner_join(movein_crime,by='NAME') %>%
  rename(Robbery10=meanRobbery,Burglary10=meanBurglary) %>%
  inner_join(leave_crime,by='NAME') %>%
  rename(Robbey00=meanRobbery,Burglary00=meanBurglary)

```


For one of our interactives, we combined movein and moveout proportion and crime rates in early years and later years with the us map dataset which contains the state name and longitude and latitude of the states. We name this new dataset used for interactive plots 'for_interactive'.

```{r eval=FALSE, message=FALSE, warning=FALSE}
movein1 <- read_csv("dataset/movein.csv")
leave1 <- read_csv("dataset/leave.csv")
movein1$d_state_name <- toupper(movein1$d_state_name)
leave1$o_state_name <- toupper(leave1$o_state_name)
early <- read_csv(here::here('dataset','00-07CrimeAvg.csv')) 
early<- early %>% filter(Area!= 'DISTRICTOFCOLUMBIA')
later <- read_csv(here::here('dataset','10-17CrimeAvg.csv'))


colnames(movein1)[1] <- "Area"
colnames(leave1)[1] <- "Area"
colnames(early)[2] <- "early_meanRobbery"
colnames(early)[3] <- "early_meanBurglary"
colnames(later)[2] <- "later_meanRobbery"
colnames(later)[3] <- "later_meanBurglary"
colnames(later)[1] <- "Area"
movein1 <- movein1 %>% filter(Area != 'DC') %>% select(Area,proportion)
leave1 <- leave1 %>% filter(Area != 'DC')%>% select(Area,proportion)
colnames(movein1)[2] <- "prop_movein"
colnames(leave1)[2] <- "prop_leave"

for_interactive <- read_csv("dataset/us map.csv")
colnames(for_interactive)[1] <- "Area"
for_interactive$Area <- gsub("(.*),.*", "\\1", for_interactive$Area) %>% toupper()


for_interactive<- for_interactive %>% inner_join(movein1,by = 'Area')
for_interactive<- for_interactive %>% inner_join(leave1,by = 'Area')
for_interactive$Area<-str_replace_all(for_interactive$Area, " ", "")
for_interactive<- for_interactive %>% inner_join(early,by = 'Area')
for_interactive<- for_interactive %>% inner_join(later,by = 'Area') 

```

To combine these data, we first read the datasets we already have which are the average crime rate in early/later years, movein/leave datasets. Then we change the column names and filtered out the DC area to make all the datasets consistent. Then we inner joined the datasets by state names (variable Area). Thus the dataset for_interactive is now ready to be used in the interactive plots.


link to [loaddata.R](https://rreproduce.netlify.app/loaddata.R)

[First Page: Introduction to Our Data](/data/)


